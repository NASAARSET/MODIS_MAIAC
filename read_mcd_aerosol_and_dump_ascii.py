#!/usr/bin/python'''Module: read_mcd_aerosol_and_dump_ascii.py==========================================================================================Disclaimer: The code is for demonstration purposes only. Users are responsible to check for accuracy and revise to fit their objective.Originally Developed by:    Justin Roberts-Pierel & Pawan Gupta, 2015 Organization:               NASA ARSETModified for Cartopy by: Amanda Markert, June 2019Organization: University of Alabama in HuntsvilleTested on Python Version: 3.7Purpose: To save a MODIS HDFEEOS file (or series of files) in ASCII format, saving time, lat, lon, and other SDS dependent on file typeSee the README associated with this module for more information.=========================================================================================='''#import necessary modulesfrom pyhdf import SDimport numpy as npimport timeimport sysimport pyprojfrom collections import OrderedDict# =============================================================================# Inputs#This uses the file "fileList.txt", containing the list of files, in order to read the filestry:    fileList=open('fileList.txt','r')except:    print('Did not find a text file containing file names (perhaps name does not match)')    sys.exit()# =============================================================================# Functions that pull metadata from HDFEOS file and extract lat/lon coordinates information# to plot data.def parse_hdfeos_metadata(string):  out = OrderedDict()  lines = [i.replace('\t','') for i in string.split('\n')]  i = -1  while i<(len(lines))-1:      i+=1      line = lines[i]      if "=" in line:          key,value = line.split('=')          if key in ['GROUP','OBJECT']:              endIdx = lines.index('END_{}={}'.format(key,value))              out[value] = parse_hdfeos_metadata("\n".join(lines[i+1:endIdx]))              i = endIdx          else:              if ('END_GROUP' not in key) and ('END_OBJECT' not in key):                   try:                       out[key] = eval(value)                   except NameError:                       out[key] = str(value)  return outdef construct_coords(ds,grid='GRID_1'):    attrs = ds.attributes()    metadata = parse_hdfeos_metadata(attrs['StructMetadata.0'])    gridInfo = metadata['GridStructure'][grid]#    gridName = gridInfo['GridName']    x1,y1 = gridInfo['UpperLeftPointMtrs']    x2,y2 = gridInfo['LowerRightMtrs']    yRes = (y1-y2)/gridInfo['YDim']    xRes = (x1-x2)/gridInfo['XDim']    #setting up coordinate grids along x and y axis    x = np.arange(x2,x1,xRes)    y = np.arange(y2,y1,yRes)[::-1]    #set up 2D grid for plotting    xx,yy = np.meshgrid(x,y)    #get projection information    if 'soid' in gridInfo['Projection'].lower():        pp = 'sinu'    else:        pp = gridInfo['Projection'].lower()        #formating projection name from metadata to pyproj for sinusoidal projection    projStr = "+proj={} +lon_0=0 +x_0=0 +y_0=0 +a={} +units=m +no_defs".format(      pp,gridInfo['ProjParams'][0])    proj = pyproj.Proj(projStr)    gcs = proj.to_latlong()    #Convert between sinusoidal project to lat/lon coord projection    lon,lat = pyproj.transform(proj,gcs,xx,yy)    #Entire dataset now have lat/lon as coordinates    return lon,lat# =============================================================================#loops through all files listed in the text filefor FILE_NAME in fileList:    FILE_NAME=FILE_NAME.strip()    user_input=input('\nWould you like to process\n' + FILE_NAME + '\n\n(Y/N)')    if(user_input == 'N' or user_input == 'n'):        continue    else:'        dataFields=dict([(1,'Optical_Depth_047'),(2,'Optical_Depth_055'),(3,'AOD_QA),(4,'Column_WV')])                try:            # open the hdf file for reading            hdf=SD.SD(FILE_NAME)        except:            print('Unable to open file: \n' + FILE_NAME + '\n Skipping...')            continue                    #Get lat and lon info        lon,lat = construct_coords(hdf)        latitude = lat.ravel()        longitude = lon.ravel()                #Get the scan start time from the hdf file. This is in number of seconds since Jan 1, 199        attrs = hdf.attributes()        scan_time = np.array((attrs['Orbit_time_stamp']).split())        #get the date info from scan_time        year=np.zeros(scan_time.shape[0])        month=np.zeros(scan_time.shape[0])        day=np.zeros(scan_time.shape[0])        hour=np.zeros(scan_time.shape[0])        min=np.zeros(scan_time.shape[0])        sensor=np.zeros(scan_time.shape[0],dtype=np.dtype('U10'))        sensor_lookup = {'T':'Terra','A':'Aqua'}        orbit=np.zeros(scan_time.shape[0]):q
        #Saves date info for each pixel         for i in range(scan_time.shape[0]):            st = scan_time[i-1]            temp=time.strptime(st[:-1],"%Y%j%H%M")            year[i-1]=temp[0]            month[i-1]=temp[1]            day[i-1]=temp[2]            hour[i-1]=temp[3]            min[i-1]=temp[4]            sensor[i-1]=sensor_lookup[st[-1]] #Sensor used for each orbit            orbit[i]=i+1 #Orbit number per file                    #Begin saving to an output array        end=9+len(dataFields)#this is the number of columns needed (based on number of SDS read)        output=np.array(np.zeros((year.shape[0]*lat.size,end)),dtype='O')        #list for the column titles        tempOutput=[]        tempOutput.append('Year')        tempOutput.append('Month')        tempOutput.append('Day')        tempOutput.append('Hour')        tempOutput.append('Minute')        tempOutput.append('Sensor')        tempOutput.append('Orbit')        tempOutput.append('Latitude')        tempOutput.append('Longitude')        #This for loop saves all of the SDS in the dictionary at the top (dependent on file type) to the array (with titles)        for i in range(9,end): #Loop through the SDS.  Below you will loop through the 4 orbits and obtain the SDS value for each            SDS_NAME=dataFields[(i-8)] # The name of the sds to read                        #get current SDS data, or exit program if the SDS is not found in the file            try:                sds=hdf.select(SDS_NAME)            except:                print('Sorry, your MODIS hdf file does not contain the SDS:',SDS_NAME,'. Please try again with the correct file type.')                continue                        attributes=sds.attributes()                        try:                scale_factor=attributes['scale_factor'] #get scale factor for current SDS            except KeyError:                scale_factor =1                        fillvalue=attributes['_FillValue']            variable = sds.get()            tempOutput.append(SDS_NAME)                        for j in range(scan_time.shape[0]): #Loop through each orbit in the file to extract information                startIdx = j*lat.size                endIdx = startIdx + lat.size                output[startIdx:endIdx,0]=int(year[j])                output[startIdx:endIdx,1]=int(month[j])                output[startIdx:endIdx,2]=int(day[j])                output[startIdx:endIdx,3]=int(hour[j])                output[startIdx:endIdx,4]=int(min[j])                output[startIdx:endIdx,5]=sensor[j]                output[startIdx:endIdx,6]=int(orbit[j])                output[startIdx:endIdx,7]=latitude[:].astype(np.float32)                output[startIdx:endIdx,8]=longitude[:].astype(np.float32)                               #Get SDS data as a vector                data=np.array(variable[j,:,:].ravel())                #The next few lines change fillvalue to NaN so that we can multiply valid values by the scale factor, then back to fill values                data=data.astype(float)                data[data==float(fillvalue)]=np.nan                data=data*scale_factor                data[np.isnan(data)]=fillvalue                #the SDS and SDS name are saved to arrays which will be written to the .txt file                output[startIdx:endIdx,i]=data                        #changes list to an array so it can be stacked            tempOutput=np.asarray(tempOutput)        #This stacks the titles on top of the data        output=np.row_stack((tempOutput,output))        #save the new array to a text file, which is the name of the HDF4 file .txt instead of .hdf        np.savetxt('{0}.txt'.format(FILE_NAME[:-4]),output,fmt='%s',delimiter=',')print('\nAll valid files have been saved successfully.')